# Chapter 07: 웹 스크래핑을 활용한 주식 데이터 수집 및 분석

## 개요

이 챕터는 **"혼자 공부하는 파이썬"** 책의 내용을 기반으로, Playwright를 사용하여 네이버 금융에서 코스피 시가총액 데이터를 웹 스크래핑하고, 수집한 데이터를 분석하여 시각화하는 프로젝트입니다.

또한, 이 챕터에는 **미니프로젝트**로 진행한 **AI 기반 주식 유형 분석기 (`app.py`)**가 포함되어 있습니다. 이 프로젝트는 수집한 주식 데이터를 K-Means 클러스터링과 t-SNE를 활용하여 자동으로 그룹화하고, OpenAI GPT를 통해 각 그룹의 특징과 투자 전략을 분석하는 Streamlit 웹 애플리케이션입니다. 자세한 내용은 하단의 [미니프로젝트 섹션](#미니프로젝트-ai-기반-주식-유형-분석기-apppy)을 참고하세요.

## 학습 내용

- **Playwright 기초**: 브라우저 자동화 및 웹 페이지 상호작용
- **웹 스크래핑**: 동적 웹 페이지에서 테이블 데이터 추출
- **데이터 전처리**: JSON 및 CSV 형식으로 데이터 저장 및 정제
- **데이터 분석**: 시가총액 기반 상위 종목 분석 및 누적 비율 계산
- **데이터 시각화**: Plotly를 활용한 트리맵(Treemap) 시각화

## 프로젝트 구조

```
Chapter_07/
├── output/              # 결과 파일 저장 디렉터리
│   ├── step_1_3.json   # 코스피 시가총액 테이블 데이터 (JSON)
│   ├── step_1_4.csv    # 정제된 코스피 시가총액 데이터 (CSV)
│   ├── step_2_2.csv    # 전체 페이지 수집 데이터 (CSV)
│   ├── step_3_1.csv    # 상위 50% 시가총액 종목 (CSV)
│   └── step_3_2.png    # 트리맵 시각화 이미지
├── step_1_1.py         # 출력 디렉터리 생성
├── step_1_2.py         # Playwright 브라우저 실행 및 기본 설정
├── step_1_3.py         # 네이버 금융에서 코스피 시가총액 테이블 데이터 수집
├── step_1_4.py         # 수집한 데이터를 CSV로 변환 및 정제
├── step_2_1.py         # 전체 페이지 수 확인
├── step_2_2.py         # 모든 페이지의 데이터 수집
├── step_3_1.py         # 상위 50% 시가총액 종목 추출 및 분석
├── step_3_2.py         # 트리맵 시각화
├── app.py              # [미니프로젝트] AI 기반 주식 유형 분석기 (Streamlit)
├── .env                # [미니프로젝트] OpenAI API 키 설정 파일
├── requirements.txt    # 필요한 패키지 목록
└── README.md           # 프로젝트 문서
```

## 실행 순서

각 스크립트는 순차적으로 실행되어야 합니다:

1. **`step_1_1.py`**: `output` 폴더를 생성합니다.
2. **`step_1_2.py`**: Playwright 브라우저를 실행하고 네이버 금융 페이지를 엽니다.
3. **`step_1_3.py`**: 코스피 시가총액 페이지로 이동하여 테이블 데이터를 수집하고 JSON으로 저장합니다.
4. **`step_1_4.py`**: JSON 데이터를 읽어 CSV로 변환하고 데이터를 정제합니다.
5. **`step_2_1.py`**: 전체 페이지 수를 확인합니다.
6. **`step_2_2.py`**: 모든 페이지의 데이터를 수집하여 하나의 CSV 파일로 저장합니다.
7. **`step_3_1.py`**: 시가총액 기준 상위 50% 종목을 추출하고 누적 비율을 계산합니다.
8. **`step_3_2.py`**: 상위 종목들을 트리맵으로 시각화하여 PNG 이미지로 저장합니다.

## 주요 기능

### 웹 스크래핑
- Playwright를 사용한 브라우저 자동화
- 동적 웹 페이지에서 테이블 데이터 추출
- 페이지네이션 처리 및 다중 페이지 데이터 수집

### 데이터 처리
- JSON 형식으로 원본 데이터 저장
- 데이터 정제 및 CSV 변환
- 시가총액 기준 정렬 및 누적 비율 계산

### 시각화
- Plotly를 활용한 트리맵 생성
- 시가총액 비율에 따른 크기 및 색상 표현
- 고해상도 이미지 저장 (1600x900, scale=2)

## 필요 라이브러리

- `playwright`: 웹 브라우저 자동화
- `pandas`: 데이터 처리 및 분석
- `plotly`: 인터랙티브 시각화
- `kaleido`: Plotly 이미지 저장을 위한 백엔드

## 설치 방법

```bash
pip install -r requirements.txt
playwright install chromium
```

## 참고사항

- 이 프로젝트는 학습 목적으로 작성되었으며, 실제 투자 결정에 사용하지 마세요.
- 웹 스크래핑 시 해당 웹사이트의 이용약관을 준수해야 합니다.
- 네이버 금융의 페이지 구조가 변경되면 코드 수정이 필요할 수 있습니다.

---

## 미니프로젝트: AI 기반 주식 유형 분석기 (app.py)

## 개요

이 프로젝트는 **Streamlit**을 활용한 웹 애플리케이션으로, KOSPI 재무 지표 데이터를 기반으로 주식들을 자동으로 그룹화하고, **OpenAI GPT**를 활용하여 각 그룹의 특징과 투자 전략을 분석하는 AI 주식 분석 도구입니다.

## 주요 기능

### 1. 데이터 업로드 및 전처리
- CSV 형식의 주식 재무 데이터 업로드
- 사용자 지정 특성 선택 (시가총액, 거래량, PER, ROE, PBR, EPS, DPS, BPS 등)
- IQR 방식의 이상치 자동 제거
- 로그 변환 및 표준화를 통한 데이터 정규화

### 2. K-Means 클러스터링
- Elbow Method를 통한 최적 군집 수(K) 자동 추천
- 사용자 지정 K 값 입력 지원
- 각 그룹의 평균 재무 지표 분석

### 3. 차원 축소 및 시각화
- **t-SNE**: 고차원 데이터를 2D/3D 공간으로 시각화
- 특성 개수에 따른 자동 시각화 방식 선택:
  - 4개 이상: t-SNE 3D 시각화
  - 3개: 3D 직접 시각화
  - 2개: 2D 산점도
  - 1개: 히스토그램
- Plotly를 활용한 인터랙티브 차트

### 4. AI 기반 분석 리포트
- OpenAI GPT-4o를 활용한 클러스터별 특징 분석
- 각 그룹의 투자자 추천 및 대표 종목 제시
- 초보자도 이해하기 쉬운 리포트 형식

## 프로젝트 구조

```
Chapter_07/
├── app.py              # Streamlit 메인 애플리케이션
├── .env                # OpenAI API 키 설정 파일 (환경변수)
├── requirements.txt    # 필요한 패키지 목록
└── README.md          # 프로젝트 문서
```

## 설치 및 실행

### 1. 필요한 패키지 설치

```bash
pip install -r requirements.txt
```

### 2. 환경변수 설정

`.env` 파일을 생성하고 OpenAI API 키를 설정합니다:

```env
OPENAI_API_KEY=your_openai_api_key_here
```

> **참고**: API 키는 [OpenAI Platform](https://platform.openai.com/api-keys)에서 발급받을 수 있습니다.

### 3. 애플리케이션 실행

```bash
streamlit run app.py
```

브라우저에서 자동으로 열리며, 기본 주소는 `http://localhost:8501`입니다.

## 사용 방법

1. **API 키 설정**
   - `.env` 파일에 API 키를 설정하면 자동으로 로드됩니다.
   - 또는 사이드바에서 직접 입력할 수 있습니다.

2. **데이터 업로드**
   - 사이드바에서 CSV 파일을 업로드합니다.
   - 파일에는 최소한 `종목명` 컬럼과 분석에 사용할 재무 지표 컬럼들이 포함되어야 합니다.

3. **특성 선택**
   - 군집화에 사용할 재무 지표를 선택합니다.
   - 기본값: 시가총액, 거래량, PER, ROE

4. **군집 수 결정**
   - Elbow Method 차트를 확인하여 최적 K 값을 파악합니다.
   - 추천값을 사용하거나 직접 입력합니다.

5. **결과 분석**
   - 각 그룹의 평균 재무 지표를 확인합니다.
   - "🤖 AI로 결과 분석하기" 버튼을 클릭하여 AI 리포트를 생성합니다.
   - 시각화 차트를 통해 그룹별 분포를 확인합니다.

## 주요 기술 스택

- **Streamlit**: 웹 애플리케이션 프레임워크
- **scikit-learn**: 머신러닝 (K-Means, StandardScaler)
- **pandas**: 데이터 처리 및 분석
- **numpy**: 수치 연산
- **plotly**: 인터랙티브 시각화
- **OpenAI API**: GPT-4o를 활용한 자연어 분석
- **python-dotenv**: 환경변수 관리

## 데이터 형식 요구사항

CSV 파일은 다음 형식을 따라야 합니다:

- 필수 컬럼: `종목명`
- 선택 가능한 재무 지표 컬럼:
  - `시가총액`: 기업의 총 가치
  - `거래량`: 거래된 주식의 총량
  - `PER`: 주가수익비율
  - `ROE`: 자기자본이익률
  - `PBR`: 주가순자산비율
  - `EPS`: 주당순이익
  - `DPS`: 주당배당금
  - `BPS`: 주당순자산

## 주의사항

- 이 도구는 **학습 및 분석 목적**으로 제작되었으며, 실제 투자 결정에 사용하지 마세요.
- OpenAI API 사용 시 비용이 발생할 수 있습니다.
- 데이터의 품질에 따라 분석 결과가 달라질 수 있습니다.
- 이상치 제거 비율이 20%를 초과하면 경고 메시지가 표시됩니다.

## 참고 자료

- [Streamlit 공식 문서](https://docs.streamlit.io/)
- [scikit-learn K-Means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
- [OpenAI API 문서](https://platform.openai.com/docs)

