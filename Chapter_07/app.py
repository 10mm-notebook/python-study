import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# --- 1. ê¸°ë³¸ í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI ì£¼ì‹ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ¤– AI ê¸°ë°˜ K-Means & t-SNE ì£¼ì‹ ìœ í˜• ë¶„ì„")
st.write("KOSPI ì¬ë¬´ ì§€í‘œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì£¼ì‹ë“¤ì„ ìë™ ê·¸ë£¹í™”í•˜ê³ , AI ì• ë„ë¦¬ìŠ¤íŠ¸ê°€ ê° ê·¸ë£¹ì˜ íŠ¹ì§•ê³¼ íˆ¬ì ì „ëµì„ ë¶„ì„í•´ì¤ë‹ˆë‹¤.")

# --- 2. ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("1. OpenAI API í‚¤")
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸° (ìš°ì„ ìˆœìœ„)
    env_api_key = os.getenv("OPENAI_API_KEY")
    
    if env_api_key and env_api_key != "your_openai_api_key_here":
        st.info("âœ… .env íŒŒì¼ì—ì„œ API í‚¤ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        api_key = env_api_key
    else:
        api_key = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password", help="API í‚¤ëŠ” ë¶„ì„ì—ë§Œ ì‚¬ìš©ë˜ë©° ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë˜ëŠ” .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    st.header("2. ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv"])
    
    st.header("3. êµ°ì§‘í™” ì„¤ì •")
    default_features = ['ì‹œê°€ì´ì•¡', 'ê±°ë˜ëŸ‰', 'PER', 'ROE']
    available_features = []
    max_k = st.slider("Elbow Method ìµœëŒ€ Kê°’", 2, 20, 10)
    
    # íŠ¹ì„± ì„¤ëª…ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    feature_descriptions = {
        'ì‹œê°€ì´ì•¡': 'ê¸°ì—…ì˜ ì´ ê°€ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì£¼ê°€ì— ì´ ë°œí–‰ ì£¼ì‹ ìˆ˜ë¥¼ ê³±í•œ ê°’ì…ë‹ˆë‹¤. ê¸°ì—…ì˜ ê·œëª¨ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ëŒ€í‘œì ì¸ ì§€í‘œì…ë‹ˆë‹¤.',
        'ê±°ë˜ëŸ‰': 'íŠ¹ì • ê¸°ê°„ ë™ì•ˆ ê±°ë˜ëœ ì£¼ì‹ì˜ ì´ëŸ‰ì…ë‹ˆë‹¤. ì‹œì¥ì˜ ê´€ì‹¬ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê±°ë˜ëŸ‰ì´ ë§ì„ìˆ˜ë¡ ìœ ë™ì„±ì´ í’ë¶€í•˜ë‹¤ê³  í•´ì„ë©ë‹ˆë‹¤.',
        'PER': 'ì£¼ê°€ìˆ˜ìµë¹„ìœ¨ (Price-to-Earnings Ratio)ë¡œ, ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœì´ìµ(EPS)ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤. ê¸°ì—…ì˜ ìˆ˜ìµì„± ëŒ€ë¹„ ì£¼ê°€ê°€ ê³ í‰ê°€ë˜ì—ˆëŠ”ì§€ ì €í‰ê°€ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤.',
        'ROE': 'ìê¸°ìë³¸ì´ìµë¥  (Return on Equity)ë¡œ, ê¸°ì—…ì´ ìê¸°ìë³¸ì„ ì´ìš©í•˜ì—¬ ì–¼ë§ˆë‚˜ íš¨ìœ¨ì ìœ¼ë¡œ ì´ìµì„ ì°½ì¶œí–ˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ìˆ˜ìµì„±ì´ ì¢‹ë‹¤ê³  í‰ê°€ë©ë‹ˆë‹¤.',
        'PBR': 'ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨ (Price-to-Book Ratio)ë¡œ, ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœìì‚°(BPS)ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤. ê¸°ì—…ì˜ ìì‚° ê°€ì¹˜ ëŒ€ë¹„ ì£¼ê°€ ìˆ˜ì¤€ì„ íŒë‹¨í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.',
        'EPS': 'ì£¼ë‹¹ìˆœì´ìµ (Earnings Per Share)ìœ¼ë¡œ, ê¸°ì—…ì˜ ìˆœì´ìµì„ ì´ ë°œí–‰ ì£¼ì‹ ìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤. 1ì£¼ë‹¹ ì°½ì¶œí•˜ëŠ” ì´ìµì˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.',
        'DPS': 'ì£¼ë‹¹ë°°ë‹¹ê¸ˆ (Dividends Per Share)ìœ¼ë¡œ, 1ì£¼ë‹¹ ì§€ê¸‰ë˜ëŠ” ë°°ë‹¹ê¸ˆì˜ ì•¡ìˆ˜ì…ë‹ˆë‹¤. ê¸°ì—…ì˜ ì£¼ì£¼ í™˜ì› ì •ì±…ì„ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì…ë‹ˆë‹¤.',
        'BPS': 'ì£¼ë‹¹ìˆœìì‚° (Book-value Per Share)ìœ¼ë¡œ, ê¸°ì—…ì˜ ì´ìì‚°ì—ì„œ ë¶€ì±„ë¥¼ ëº€ ìˆœìì‚°ì„ ì´ ë°œí–‰ ì£¼ì‹ ìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤. ê¸°ì—…ì˜ ì¬ë¬´ ì•ˆì •ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.'
    }
    
    with st.expander("ğŸ’¡ ê° Feature ì„¤ëª… ë³´ê¸°"):
        for feature, desc in feature_descriptions.items():
            st.markdown(f"**{feature}**: {desc}")

    st.info("**Pro-Tip:** 'ì‹œê°€ì´ì•¡', 'ê±°ë˜ëŸ‰' ë“± ê·œëª¨ ê´€ë ¨ íŠ¹ì„±ì„ ì œì™¸í•˜ê³  'PER', 'ROE' ë“± ì§ˆì  íŠ¹ì„±ë§Œìœ¼ë¡œ ë¶„ì„í•˜ë©´ ìƒˆë¡œìš´ ê´€ì ì˜ ê·¸ë£¹ì„ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.header("4. ë°ì´í„° ì •ì œ ì„¤ì •")
    remove_outliers_option = st.checkbox("ì´ìƒì¹˜ ìë™ ì œê±° (IQR ë°©ì‹)", value=True)

# --- 3. ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
@st.cache_data
def preprocess_data(df, features_to_use, remove_outliers):
    df_clean = df[features_to_use].copy()
    for col in features_to_use:
        if df_clean[col].dtype == 'object':
            df_clean[col] = df_clean[col].str.replace(',', '', regex=False)
        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')

    df_clean.dropna(inplace=True)
    if df_clean.empty: return None, None, None, 0

    initial_rows = len(df_clean)
    if remove_outliers:
        # ì´ìƒì¹˜ë¥¼ í•œ ë²ˆì— ëª¨ì•„ì„œ ì œê±°í•˜ê¸° ìœ„í•œ ë¡œì§
        outlier_indices = set()
        for col in features_to_use:
            Q1 = df_clean[col].quantile(0.25)
            Q3 = df_clean[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 2.5 * IQR
            upper_bound = Q3 + 2.5 * IQR
            # í•´ë‹¹ íŠ¹ì„±ì—ì„œ ì´ìƒì¹˜ì¸ í–‰ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŒ
            col_outliers = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)].index
            # ì „ì²´ ì´ìƒì¹˜ ì¸ë±ìŠ¤ ì§‘í•©ì— ì¶”ê°€ (ì¤‘ë³µì€ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨)
            outlier_indices.update(col_outliers)
        
        # ì‹ë³„ëœ ëª¨ë“  ì´ìƒì¹˜ë¥¼ ë§ˆì§€ë§‰ì— í•œ ë²ˆì— ì œê±°
        df_clean = df_clean.drop(index=outlier_indices)
        outliers_removed = initial_rows - len(df_clean)
        if initial_rows > 0:
            removal_rate = outliers_removed / initial_rows
            if removal_rate > 0.2:  # 20% ì´ìƒ ì œê±°ì‹œ ê²½ê³ 
                st.warning(f"âš ï¸ ì „ì²´ ë°ì´í„°ì˜ {removal_rate:.1%}ê°€ ì´ìƒì¹˜ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. ì„ê³„ê°’ ì¡°ì •ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
    else:
        outliers_removed = 0

    if df_clean.empty: return None, None, None, outliers_removed

    df_for_scaling = df_clean.copy()
    log_transform_cols = ['ì‹œê°€ì´ì•¡', 'ê±°ë˜ëŸ‰', 'ìì‚°ì´ê³„', 'ë§¤ì¶œì•¡']
    for col in log_transform_cols:
        if col in df_for_scaling.columns:
            df_for_scaling[col] = df_for_scaling[col].apply(lambda x: np.log1p(x) if x > 0 else 0)

    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(df_for_scaling)
    return df_clean, features_scaled, df_clean.index, outliers_removed

# --- 4. ìµœì  K íƒìƒ‰ í•¨ìˆ˜ ---
@st.cache_data
def find_optimal_k(_scaled_data, max_k_val):
    inertias = []
    for k in range(1, max_k_val + 1):
        kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10).fit(_scaled_data)
        inertias.append(kmeans.inertia_)
    try:
        deltas = [inertias[i] - inertias[i+1] for i in range(len(inertias)-1)]
        delta_deltas = [deltas[i] - deltas[i+1] for i in range(len(deltas)-1)]
        optimal_k = delta_deltas.index(max(delta_deltas)) + 2
    except: optimal_k = 4
    fig = go.Figure(data=go.Scatter(x=list(range(1, max_k_val + 1)), y=inertias, mode='lines+markers'))
    fig.add_vline(x=optimal_k, line_width=2, line_dash="dash", line_color="red", annotation_text=f"ì•Œê³ ë¦¬ì¦˜ ì¶”ì²œ K = {optimal_k}")
    fig.update_layout(title='<b>Elbow Method</b>', xaxis_title='êµ°ì§‘ ìˆ˜(K)', yaxis_title='ì´ë„ˆì…”(Inertia)')
    return fig, optimal_k

# --- 5. GPT ë¶„ì„ í•¨ìˆ˜ ---
@st.cache_data
def analyze_clusters_with_gpt(cluster_summary_df, top_stocks_per_cluster):
    client = OpenAI(api_key=api_key)
    summary_md = cluster_summary_df.to_markdown()
    
    prompt = f"""
    ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ì£¼ì‹ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” K-Means êµ°ì§‘í™”ë¡œ ë„ì¶œëœ ì£¼ì‹ í´ëŸ¬ìŠ¤í„°ë“¤ì˜ í‰ê·  ì¬ë¬´ ì§€í‘œì™€ ê° í´ëŸ¬ìŠ¤í„°ì˜ ëŒ€í‘œ ì¢…ëª©ì…ë‹ˆë‹¤.

    **[í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ì¬ë¬´ ì§€í‘œ]**
    {summary_md}

    **[í´ëŸ¬ìŠ¤í„°ë³„ ëŒ€í‘œ ì¢…ëª©]**
    {top_stocks_per_cluster}

    **[ë¶„ì„ ìš”ì²­]**
    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê° í´ëŸ¬ìŠ¤í„°ì˜ íŠ¹ì§•ì„ ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ë¶„ì„í•˜ê³ , ì–´ë–¤ ì„±í–¥ì˜ íˆ¬ììì—ê²Œ ì í•©í• ì§€ ì¶”ì²œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”.

    --- 
    ### ğŸ¤– AI ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸

    **ê·¸ë£¹ 0: (ê·¸ë£¹ì˜ íŠ¹ì§•ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½. ì˜ˆ: ì•ˆì •ì ì¸ ëŒ€í˜• ê°€ì¹˜ì£¼)**
    *   **íŠ¹ì§•:** (êµ¬ì²´ì ì¸ ì¬ë¬´ ì§€í‘œë¥¼ ê·¼ê±°ë¡œ ê·¸ë£¹ì˜ íŠ¹ì§•ì„ 2-3ê°€ì§€ ì„œìˆ )
    *   **íˆ¬ìì ì¶”ì²œ:** (ì–´ë–¤ íˆ¬ì ì„±í–¥ì˜ ì‚¬ëŒì—ê²Œ ì´ ê·¸ë£¹ì˜ ì£¼ì‹ë“¤ì´ ë§¤ë ¥ì ì¼ì§€ ì„œìˆ )
    *   **ëŒ€í‘œ ì¢…ëª©:** (í•´ë‹¹ ê·¸ë£¹ì˜ ëŒ€í‘œ ì¢…ëª© 2-3ê°œë¥¼ ì–¸ê¸‰)

    **ê·¸ë£¹ 1: (ê·¸ë£¹ì˜ íŠ¹ì§•ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½)**
    *   **íŠ¹ì§•:** ...
    *   **íˆ¬ìì ì¶”ì²œ:** ...
    *   **ëŒ€í‘œ ì¢…ëª©:** ...

    (ì´í•˜ ê·¸ë£¹ ìˆ˜ë§Œí¼ ë°˜ë³µ)
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# --- 6. ë©”ì¸ ë¡œì§ ---
if uploaded_file is not None:
    if not api_key:
        st.warning("OpenAI API í‚¤ë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ì£¼ì„¸ìš”. API í‚¤ê°€ ì—†ìœ¼ë©´ AI ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    try:
        df_raw = pd.read_csv(uploaded_file, encoding='utf-8')
        with st.sidebar:
            features_selected = st.multiselect("êµ°ì§‘í™”ì— ì‚¬ìš©í•  íŠ¹ì„±ì„ ì„ íƒí•˜ì„¸ìš”.", options=[c for c in df_raw.columns if c != 'ì¢…ëª©ëª…'], default=[f for f in default_features if f in df_raw.columns])

        if features_selected:
            df_clean, data_scaled, processed_indices, outliers_count = preprocess_data(df_raw, features_selected, remove_outliers_option)
            if df_clean is not None and not df_clean.empty:
                if remove_outliers_option: st.success(f"ì´ìƒì¹˜ ì œê±° ì™„ë£Œ: ì´ {outliers_count}ê°œì˜ ì´ìƒì¹˜ë¥¼ ë¶„ì„ì—ì„œ ì œì™¸í–ˆìŠµë‹ˆë‹¤.")
                
                st.header("ğŸ“Š 1. ìµœì ì˜ êµ°ì§‘ ìˆ˜ (K) ê²°ì •")
                elbow_fig, suggested_k = find_optimal_k(data_scaled, max_k)
                st.plotly_chart(elbow_fig, use_container_width=True)
                st.markdown("--- ")
                st.subheader("ë¶„ì„ì— ì‚¬ìš©í•  êµ°ì§‘ ìˆ˜(K)ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.")
                manual_k = st.number_input("K ê°’ ì…ë ¥", 2, 20, suggested_k)

                kmeans = KMeans(n_clusters=manual_k, init='k-means++', random_state=42, n_init=10).fit(data_scaled)
                df_result = df_raw.loc[processed_indices].copy()
                df_result['cluster'] = kmeans.labels_.astype(str)

                st.header(f"ğŸ“ˆ 2. K = {manual_k}ì¼ ë•Œì˜ êµ°ì§‘í™” ê²°ê³¼ ë¶„ì„")
                cluster_summary = df_clean.assign(cluster=kmeans.labels_).groupby('cluster')[features_selected].mean()
                st.subheader("ê° ê·¸ë£¹ì˜ í‰ê· ì ì¸ íŠ¹ì§•")
                st.dataframe(cluster_summary.style.background_gradient(cmap='viridis'))

                # GPT ë¶„ì„ ì„¹ì…˜
                if st.button("ğŸ¤– AIë¡œ ê²°ê³¼ ë¶„ì„í•˜ê¸°", help="í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ GPTì— ì „ì†¡í•˜ì—¬ ê·¸ë£¹ë³„ íŠ¹ì§•ê³¼ íˆ¬ì ì „ëµì„ ë¶„ì„í•©ë‹ˆë‹¤."):
                    if not api_key: st.error("OpenAI API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
                    else:
                        top_stocks = {f"ê·¸ë£¹ {i}": df_result[df_result['cluster'] == str(i)]['ì¢…ëª©ëª…'].head(5).tolist() for i in range(manual_k)}
                        with st.spinner('AI ì• ë„ë¦¬ìŠ¤íŠ¸ê°€ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                            gpt_report = analyze_clusters_with_gpt(cluster_summary, top_stocks)
                            st.info(gpt_report)

                st.header("âœ¨ 3. ì¢…í•© êµ°ì§‘ ì‹œê°í™”")
                # (ì´í•˜ ì‹œê°í™” ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
                n_features = data_scaled.shape[1]
                if n_features >= 4:
                    st.subheader("t-SNE 3D ì‹œê°í™” (4ê°œ ì´ìƒ íŠ¹ì„±)")
                    with st.spinner('ê³ ì°¨ì› ë°ì´í„°ë¥¼ 3D ê³µê°„ìœ¼ë¡œ ë³€í™˜ì¤‘ (t-SNE)...'):
                        tsne = TSNE(
                            n_components=3, 
                            random_state=42, 
                            perplexity=min(30, max(5, len(df_result)//4)),
                            max_iter=1000,  # ê¸°ë³¸ê°’ ì¡°ì •
                            learning_rate='auto'  # ìë™ í•™ìŠµë¥ 
                        )
                        features_3d = tsne.fit_transform(data_scaled)
                        df_result['x'], df_result['y'], df_result['z'] = features_3d[:, 0], features_3d[:, 1], features_3d[:, 2]

                        fig = px.scatter_3d(df_result, x='x', y='y', z='z', color='cluster', hover_name='ì¢…ëª©ëª…', hover_data=features_selected, title='t-SNEë¡œ ì°¨ì› ì¶•ì†Œëœ 3D êµ°ì§‘ ë¶„í¬')
                        st.plotly_chart(fig, use_container_width=True)
                elif n_features == 3:
                    st.subheader("3D íŠ¹ì„± ì§ì ‘ ì‹œê°í™”")
                    x_axis, y_axis, z_axis = features_selected[0], features_selected[1], features_selected[2]
                    fig = px.scatter_3d(df_result, x=x_axis, y=y_axis, z=z_axis, color='cluster', hover_name='ì¢…ëª©ëª…', hover_data=features_selected, title=f'{x_axis}, {y_axis}, {z_axis} ê¸°ì¤€ 3D êµ°ì§‘ ë¶„í¬')
                    st.plotly_chart(fig, use_container_width=True)
                elif n_features == 2:
                    st.subheader("2D íŠ¹ì„± ì§ì ‘ ì‹œê°í™”")
                    x_axis, y_axis = features_selected[0], features_selected[1]
                    df_result_scaled = df_result.copy()
                    df_result_scaled[features_selected] = data_scaled 
                    fig = px.scatter(df_result, x=x_axis, y=y_axis, color='cluster', hover_name='ì¢…ëª©ëª…', hover_data=features_selected, title=f'{x_axis}ì™€ {y_axis} ê¸°ì¤€ êµ°ì§‘ ë¶„í¬')
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.subheader("1D íŠ¹ì„± ë¶„í¬ ì‹œê°í™”")
                    x_axis = features_selected[0]
                    fig = px.histogram(df_result, x=x_axis, color='cluster', marginal="box", hover_name='ì¢…ëª©ëª…', title=f'{x_axis}ì˜ ê·¸ë£¹ë³„ ë¶„í¬')
                    st.plotly_chart(fig, use_container_width=True)

                st.header("ğŸ“‚ 4. ê° ê·¸ë£¹ì— ì†í•œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸")
                for i in sorted(df_result['cluster'].unique()):
                    with st.expander(f"**ê·¸ë£¹ {i}**ì— ì†í•œ ì¢…ëª©ë“¤ (ì´ {len(df_result[df_result['cluster'] == i])}ê°œ)"):
                        st.dataframe(df_result[df_result['cluster'] == i].head(20))
            else:
                st.error("ë°ì´í„° ì „ì²˜ë¦¬ í›„ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
else:
    st.info("ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ì…ë ¥í•˜ê³ , KOSPI ë°ì´í„° CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")