

import os
import requests
import datetime
import re

def fetch_job_postings(api_key, start_date, end_date):
    """ê¸ˆìœµê°ë…ì› APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì§€ì •ëœ ê¸°ê°„ì˜ ì±„ìš© ê³µê³ ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    
    url = (
        f"https://www.fss.or.kr/fss/kr/openApi/api/recruitInfo.jsp"
        f"?apiType=json&startDate={start_date}&endDate={end_date}&authKey={api_key}"
    )
    
    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        
        if data.get("reponse", {}).get("resultCode") == "1":
            return data["reponse"].get("result", [])
        else:
            if data.get("reponse", {}).get("resultMsg") != "ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.":
                 print(f"API Error: {data.get('reponse', {}).get('resultMsg', 'Unknown error')}")
            return []
            
    except requests.exceptions.RequestException as e:
        print(f"HTTP Request failed: {e}")
        return []
    except ValueError:
        print(f"Failed to decode JSON from response: {response.text}")
        return []

def generate_markdown_section(title, jobs):
    """ì±„ìš© ê³µê³  ë¦¬ìŠ¤íŠ¸ë¡œ ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ í•˜ë‚˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not jobs:
        return f"### {title}\n\n- í•´ë‹¹ ê¸°ê°„ì— ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.\n"

    table = f"### {title}\n\n"
    table += "| ê¸°ê´€ëª… | ì œëª© | ë§ˆê°ì¼ | ë§í¬ |\n"
    table += "|---|---|---|---|\n"
    
    for job in sorted(jobs, key=lambda x: x.get('recpEndDay', ''), reverse=True):
        title_text = job.get('titl', 'N/A').replace('\n', ' ').strip()
        # ë§ˆê°ì¼ì´ ì—†ëŠ” ê²½ìš° 'ì±„ìš© ì‹œ'ë¡œ í‘œì‹œ
        end_day = job.get('recpEndDay', 'N/A')
        if not end_day or end_day == 'N/A':
            end_day = 'ì±„ìš© ì‹œ'

        link = job.get('siteUrl') if job.get('siteUrl') else job.get('originUrl', '#')
        table += f"| {job.get('instNm', 'N/A')} | {title_text} | {end_day} | [ë°”ë¡œê°€ê¸°]({link}) |\n"
        
    return table

def update_readme(markdown_content):
    """README.md íŒŒì¼ì˜ ë‚´ìš©ì„ ìƒˆë¡œìš´ ì±„ìš© ê³µê³ ë¡œ êµì²´í•©ë‹ˆë‹¤."""
    readme_path = 'README.md'  # ë£¨íŠ¸ README.md íŒŒì¼ë¡œ ê²½ë¡œ ë³€ê²½
    placeholder_start = "<!-- START_JOBS -->"
    placeholder_end = "<!-- END_JOBS -->"

    try:
        with open(readme_path, 'r', encoding='utf-8') as f:
            full_content = f.read()

        now_utc = datetime.datetime.utcnow()
        now_kst = now_utc + datetime.timedelta(hours=9)
        header = f"## ğŸ“… ê¸ˆìœµê¶Œ ì±„ìš© ê³µê³  (ìµœê·¼ ì—…ë°ì´íŠ¸: {now_kst.strftime('%Y-%m-%d %H:%M:%S')})\n\n"
        jobs_section = f"{placeholder_start}\n{header}{markdown_content}\n{placeholder_end}"

        # ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ placeholder ì‚¬ì´ì˜ ë‚´ìš©ë§Œ êµì²´
        pattern = re.compile(f"{re.escape(placeholder_start)}.*?{re.escape(placeholder_end)}", re.DOTALL)
        
        if pattern.search(full_content):
            final_content = pattern.sub(jobs_section, full_content)
        else:
            # í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì—†ëŠ” ê²½ìš° íŒŒì¼ ëì— ì¶”ê°€ (ë˜ëŠ” ë‹¤ë¥¸ ì›í•˜ëŠ” ë™ì‘)
            final_content = full_content + "\n" + jobs_section

        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(final_content)
        
        print(f"Successfully wrote {len(final_content)} characters to {readme_path}")

    except FileNotFoundError:
        # ë£¨íŠ¸ì— README.mdê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ìƒˆë¡œ ìƒì„±
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(jobs_section)
        print(f"Created {readme_path} and wrote {len(jobs_section)} characters.")


if __name__ == "__main__":
    api_key = os.getenv("FSS_API_KEY")
    
    if not api_key:
        raise ValueError("API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜(FSS_API_KEY)ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    today = datetime.date.today()

    all_fetched_jobs = {} # Use a dictionary to store jobs by appformNo for deduplication

    # Fetch data for the past year in 30-day chunks
    # Start from 1 month in the future to cover current jobs and go back 1 year
    current_date_iterator = today + datetime.timedelta(days=30) 
    end_of_historical_period = today - datetime.timedelta(days=365) 

    while current_date_iterator > end_of_historical_period:
        interval_end_date = current_date_iterator
        interval_start_date = interval_end_date - datetime.timedelta(days=30)

        # Ensure start date doesn't go beyond the desired historical period
        if interval_start_date < end_of_historical_period:
            interval_start_date = end_of_historical_period

        print(f"Fetching jobs from {interval_start_date.strftime('%Y-%m-%d')} to {interval_end_date.strftime('%Y-%m-%d')}")
        jobs_in_interval = fetch_job_postings(
            api_key,
            interval_start_date.strftime('%Y-%m-%d'),
            interval_end_date.strftime('%Y-%m-%d')
        )

        for job in jobs_in_interval:
            appform_no = job.get('appformNo')
            if appform_no:
                all_fetched_jobs[appform_no] = job # Add or update job, effectively deduplicating

        current_date_iterator = interval_start_date - datetime.timedelta(days=1) # Move to the day before the start of the current interval

    all_jobs = list(all_fetched_jobs.values()) # Convert dictionary values back to a list

    current_jobs = []
    closed_jobs = []

    for job in all_jobs:
        end_day_str = job.get('recpEndDay')
        
        if end_day_str == 'ì±„ìš© ì‹œ': # ë§ˆê°ì¼ì´ 'ì±„ìš© ì‹œ'ì¸ ê²½ìš°
            current_jobs.append(job)
        elif not end_day_str: # ë§ˆê°ì¼ì´ ì•„ì˜ˆ ì—†ëŠ” ê²½ìš°
            current_jobs.append(job)
        else:
            try:
                end_day = datetime.datetime.strptime(end_day_str, '%Y-%m-%d').date()
                if end_day >= today: # ë§ˆê°ì¼ì´ ì˜¤ëŠ˜ì´ê±°ë‚˜ ë¯¸ë˜ì¸ ê²½ìš°
                    current_jobs.append(job)
                else: # ë§ˆê°ì¼ì´ ê³¼ê±°ì¸ ê²½ìš°
                    closed_jobs.append(job)
            except ValueError:
                # ë‚ ì§œ í˜•ì‹ì´ 'ì±„ìš© ì‹œ'ë„ ì•„ë‹ˆê³ , ë¹„ì–´ìˆì§€ë„ ì•Šìœ¼ë©°, ì˜ëª»ëœ ê²½ìš°
                current_jobs.append(job) # ì¼ë‹¨ ì§„í–‰ ì¤‘ì¸ ê³µê³ ë¡œ ë¶„ë¥˜

    # ë§ˆí¬ë‹¤ìš´ ìƒì„±
    current_section = generate_markdown_section("ğŸš€ ì§„í–‰ ì¤‘ì¸ ê³µê³ ", current_jobs)
    closed_section = generate_markdown_section("âœ… ìµœê·¼ ë§ˆê°ëœ ê³µê³ ", closed_jobs)
    
    final_markdown = current_section + "\n" + closed_section
    
    update_readme(final_markdown)
