

import os
import requests
import datetime
import re

def fetch_job_postings(api_key, start_date, end_date):
    """ê¸ˆìœµê°ë…ì› APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì§€ì •ëœ ê¸°ê°„ì˜ ì±„ìš© ê³µê³ ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    
    url = (
        f"https://www.fss.or.kr/fss/kr/openApi/api/recruitInfo.jsp"
        f"?apiType=json&startDate={start_date}&endDate={end_date}&authKey={api_key}"
    )
    
    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        
        if data.get("reponse", {}).get("resultCode") == "1":
            return data["reponse"].get("result", [])
        else:
            if data.get("reponse", {}).get("resultMsg") != "ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.":
                 print(f"API Error: {data.get('reponse', {}).get('resultMsg', 'Unknown error')}")
            return []
            
    except requests.exceptions.RequestException as e:
        print(f"HTTP Request failed: {e}")
        return []
    except ValueError:
        print(f"Failed to decode JSON from response: {response.text}")
        return []

def generate_markdown_section(title, jobs):
    """ì±„ìš© ê³µê³  ë¦¬ìŠ¤íŠ¸ë¡œ ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ í•˜ë‚˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not jobs:
        return f"### {title}\n\n- í•´ë‹¹ ê¸°ê°„ì— ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.\n"

    table = f"### {title}\n\n"
    table += "| ê¸°ê´€ëª… | ì œëª© | ë§ˆê°ì¼ | ë§í¬ |\n"
    table += "|---|---|---|---|\n"
    
    for job in sorted(jobs, key=lambda x: x.get('recpEndDay', ''), reverse=True):
        title_text = job.get('titl', 'N/A').replace('\n', ' ').strip()
        link = job.get('siteUrl') if job.get('siteUrl') else job.get('originUrl', '#')
        table += f"| {job.get('instNm', 'N/A')} | {title_text} | {job.get('recpEndDay', 'N/A')} | [ë°”ë¡œê°€ê¸°]({link}) |\n"
        
    return table

def update_readme(markdown_content):
    """README.md íŒŒì¼ì˜ ë‚´ìš©ì„ ìƒˆë¡œìš´ ì±„ìš© ê³µê³ ë¡œ êµì²´í•©ë‹ˆë‹¤."""
    readme_path = 'Chapter_10/README.md'
    placeholder_start = "<!-- START_JOBS -->"
    placeholder_end = "<!-- END_JOBS -->"

    try:
        with open(readme_path, 'r', encoding='utf-8') as f:
            full_content = f.read()

        if placeholder_start in full_content:
            intro_content = full_content.split(placeholder_start)[0]
        else:
            intro_content = full_content # í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ì†Œê°œê¸€ë¡œ ê°„ì£¼

        header = f"## ğŸ“… ê¸ˆìœµê¶Œ ì±„ìš© ê³µê³  (ìµœê·¼ ì—…ë°ì´íŠ¸: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n\n"
        jobs_section = f"{placeholder_start}\n{header}{markdown_content}\n{placeholder_end}"

        final_content = intro_content + jobs_section

        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(final_content)
        
        print(f"Successfully wrote {len(final_content)} characters to {readme_path}")

    except FileNotFoundError:
        print(f"Error: {readme_path} not found. Cannot update.")


if __name__ == "__main__":
    api_key = os.getenv("FSS_API_KEY")
    
    if not api_key:
        raise ValueError("API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜(FSS_API_KEY)ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    today = datetime.date.today()
    
    start_current = today
    end_current = today + datetime.timedelta(days=30)
    current_jobs = fetch_job_postings(api_key, start_current.strftime('%Y-%m-%d'), end_current.strftime('%Y-%m-%d'))
    
    end_closed = today - datetime.timedelta(days=1)
    start_closed = end_closed - datetime.timedelta(days=30)
    closed_jobs = fetch_job_postings(api_key, start_closed.strftime('%Y-%m-%d'), end_closed.strftime('%Y-%m-%d'))

    current_section = generate_markdown_section("ğŸš€ ì§„í–‰ ì¤‘ì¸ ê³µê³ ", current_jobs)
    closed_section = generate_markdown_section("âœ… ìµœê·¼ ë§ˆê°ëœ ê³µê³ ", closed_jobs)
    
    final_markdown = current_section + "\n" + closed_section
    
    update_readme(final_markdown)
